# -*- coding: utf-8 -*-
"""manifold_clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11j16mhZbaPT_2RA7rb6F1c5JRcn2RMYe

# Imports
In this section we'll import all the necessary libraries, such as
- numpy for matrix manipulation and arithmetic
- pytorch, the main library for machine learning we'll use
- matplotlib to plot our results

## The libraries
"""

# Matplotlib and numpy
import matplotlib.pyplot as plt
import numpy as np

# torch, datasets and its utilities
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import random
import argparse

# switch to gpu if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print('Using device: ', device)

# setting random seeds for reproducibility
torch.manual_seed(0)
np.random.seed(0)
random.seed(0)

print("""## The dataset

In the following section we'll import our train and test datasets, in
order to do so we need the loaders for both the test and train data """)

from torchvision import datasets as dts
from torchvision.transforms import ToTensor 

train_data = dts.MNIST(
    root = 'data',
    train = True,                         
    transform = ToTensor(), 
    download = True,            
)

test_data = dts.MNIST(
    root = 'data', 
    train = False, 
    transform = ToTensor()
)

train_loader = torch.utils.data.DataLoader(
    train_data, 
    batch_size=128, 
    shuffle=True,
)

test_loader = torch.utils.data.DataLoader(
    test_data, 
    batch_size=20, 
    shuffle=True
)
print("""## Loading and saving data

Since this file is a standalone executable might be useful to have a
way of loading and saving training weights for the autoencoder (in
order not to train it every time). """)


parser = argparse.ArgumentParser(
    description='Manifold clustering',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('--load', default=None, type=str)
parser.add_argument('--save', default=None, type=str)
parser.add_argument('--no_shallow', default=False, action="store_true")
parser.add_argument('--no_umap', default=False, action="store_true")
parser.add_argument('--no_tsne', default=False, action="store_true")
parser.add_argument('--no_isomap', default=False, action="store_true")
args = parser.parse_args()

print("""# The autoencoder

As described in the paper, the first component of our model is the
autoencoder, takes as input the image as an array of dimensionality
(1, 784) and ideally should output the same image. The rationale
behind the structuring of this component in such a way (2 bottleneck
layers of 500 units, an intermediate hidden layer of 2000 units and
then the dual decoder) is described in the report of the project.

## The encoder

The encoder component of the autoencoder is responsible to encode the
input data into vectors of different dimensionality, the bottleneck (2
units of lower dimensionality as the input) force the encoder to
actually select the features it considers most important from the raw
data, the output (2000 unit) allows to breathe (?)

""")

class Encoder(nn.Module):
    def __init__(self, shape):
        super().__init__()
        self.encoder_hidden_layer_1 = nn.Linear(
            in_features=shape, out_features=500
        )
        self.encoder_hidden_layer_2 = nn.Linear(
            in_features=500, out_features=500
        )
        self.encoder_output_layer = nn.Linear(
            in_features=500, out_features=2000
        )

    def forward(self, features):
        activation = self.encoder_hidden_layer_1(features)
        activation = torch.relu(activation)
        activation = self.encoder_hidden_layer_2(activation)
        activation = torch.relu(activation)
        code = self.encoder_output_layer(activation)
        code = torch.sigmoid(code)
        return code

print("""## The decoder

Can be considered as the other side of the collaborative network
encoder-decoder, and has the job of better turn the encoding given by
the encoder into the initial data. Is very important in order to train
the encoder to find the best possible features to rapresent in order
to get the best possible encoding.  """)

class Decoder(nn.Module):
    def __init__(self, shape):
        super().__init__()
        self.decoder_hidden_layer_1 = nn.Linear(
            in_features=2000, out_features=500
        )
        self.decoder_hidden_layer_2 = nn.Linear(
            in_features=500, out_features=500
        )
        self.decoder_output_layer = nn.Linear(
            in_features=500, out_features=shape
        )

    def forward(self, code):
        activation = self.decoder_hidden_layer_1(code)
        activation = torch.relu(activation)
        activation = self.decoder_hidden_layer_2(activation)
        activation = torch.relu(activation)
        activation = self.decoder_output_layer(activation)
        reconstructed = torch.sigmoid(activation)
        return reconstructed

print("""## The autoencoder
The resulting network is the combination of the two
""")

class AE(nn.Module):
    def __init__(self, shape):
        super().__init__()
        self.encoder = Encoder(shape)
        self.decoder = Decoder(shape)

    def forward(self, features):
        code = self.encoder.forward(features)
        reconstructed = self.decoder.forward(code)
        return reconstructed

print("""We can now instanciate our model""")

# create a model from `AE` autoencoder class
# load it to the specified device, either gpu or cpu
model = AE(784).to(device)

# create an optimizer object
# Adam optimizer with learning rate 1e-3
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# mean-squared error loss
criterion = nn.MSELoss()

print("""and train it""")

epochs = 20

if args.load is None:
    for epoch in range(epochs):
        loss = 0
        for x, _ in train_loader:
            x = x.view(-1, 784).to(device)
            optimizer.zero_grad()
            outputs = model(x)
            train_loss = criterion(outputs, x)
            train_loss.backward()
            optimizer.step()
            loss += train_loss.item()

        loss = loss / len(train_loader)
        print("epoch : {}/{}, loss = {:.6f}".format(epoch + 1, epochs, loss))
    if args.save is not None:
        torch.save(model.state_dict(), args.save)
else:
    model.load_state_dict(torch.load(args.load))
print("""## Test the autoencoder

The autoencoder can now be tested in order to get a rough
understanding of weather it is good enough on reconstructing images or
not.

On top there are the initial images, and below the reconstructed
ones. As we can see the accuracy became pretty high.  """)

test_examples = None
model.eval()

# Test it over the first data of the test dataset
with torch.no_grad():
    for batch_features in test_loader:
        batch_features = batch_features[0].to(device)
        test_examples = batch_features.view(-1, 784)
        reconstruction = model(test_examples)
        break

# Plot results
with torch.no_grad():
    number = 10
    plt.figure(figsize=(20, 4))
    for index in range(number):
        # display original
        ax = plt.subplot(2, number, index + 1)
        plt.imshow(test_examples[index].cpu().numpy().reshape(28, 28))
        plt.gray()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

        # display reconstruction
        ax = plt.subplot(2, number, index + 1 + number)
        plt.imshow(reconstruction[index].cpu().numpy().reshape(28, 28))
        plt.gray()
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
    plt.show()

print("""## Passing to the manifold learners

What we're really interested on is the output of the encoder layer. So
let's split the autoencoder component and provider its output as input
for the next component: the manifold learner.  """)

encoder = model.encoder
encoder.eval()

with torch.no_grad():
    for batch_features in test_loader:
        batch_features = batch_features[0].to(device)
        test_examples = batch_features.view(-1, 784)
        hl = encoder(test_examples)

print("""# Manifold learners

A number of manifold learner are available trough different libraries:
We'll use

- scikit learn for Isomap (global manifold focus)
- umap for umap (local manifold focus, good at global manifold)
- scikit learn for t-SNE (local manifold focus)

We'll have to install umap, as it does not come with the default colab
environment

## UMAP: 

Uniform Manifold Approximation and Projection As already stated this
algorithm finds a low dimensional embedding of the data that
approximates an underlying manifold, has a focus on the local manifold
while still providing a good rapresentation of the global structure.

""")

# !pip install umap umap-learn

import umap

umap_manifold = umap.UMAP(
          random_state=0,
          metric='euclidean',
          n_components=2,
          n_neighbors=20,
          min_dist=0.0)

print("""## t-SNE: 

t-distributed Stochastic Neighbor Embedding Is a non-linear method
with the objective of optimize for local distances when creating the
embedding. To do so we will use the scikit learn library, as it
provides support for it.

""")

# !pip install MulticoreTSNE

try:
    from MulticoreTSNE import MulticoreTSNE as TSNE
except:
    from sklearn.manifold import TSNE

tsne_manifold = TSNE(
    n_components=2,
    n_jobs=16,
    random_state=0)

# The fit outputs some warnings as current (9 Jan 2023), but I choose to ignore
# them since they are notices about future changes in the API 
# (default parameters)

print("""## Isomap

Isomap is another non-linear method with the objective to optimze for
global manifold rather than local. Is included in the experiment in
order to validate the idea that the embedding of a local manifold is
better suited for this task

""")

# !pip install sklearn

from sklearn.manifold import Isomap

isomap_manifold = Isomap(
    n_components=10,
    n_neighbors=5)

print("""# Clustering

Final passage of our process is the clustering of the embedded data,
to do so we'll try different methods: the Gaussian Mixture Models
(GMM). It is a shallow method for clustering, tuned in order to build
10 clusters (number of digits in the dataset) and set to a random
state of 0 for reproducibility.

""")

from sklearn.mixture import GaussianMixture
from sklearn.cluster import KMeans

gmm = GaussianMixture(
    covariance_type='full',
    n_components=10,
    random_state=0)

km = KMeans(
    init='k-means++',
    n_clusters=10,
    random_state=0,
    n_init=20)

print("""## Metrics

In order to evaluate the resulting clustering we'll rely on the notion
of accuracy and Normalized mutual information. While NMI is easily
calculated trough the metrics module of the scikit library, for the
accuracy we have to define the measure ourselves

""")

from scipy.optimize import linear_sum_assignment

def linear_assignment(cost_matrix):
    x, y = linear_sum_assignment(cost_matrix)
    return np.array(list(zip(x, y)))

def best_cluster_fit(y_true, y_pred):
    y_true = y_true.astype(np.int64)
    D = max(y_pred.max(), y_true.max()) + 1
    w = np.zeros((D, D), dtype=np.int64)
    for i in range(y_pred.size):
        w[y_pred[i], y_true[i]] += 1

    ind = linear_assignment(w.max() - w)
    best_fit = []
    for i in range(y_pred.size):
        for j in range(len(ind)):
            if ind[j][0] == y_pred[i]:
                best_fit.append(ind[j][1])
    return best_fit, ind, w


def cluster_acc(y_true, y_pred):
    _, ind, w = best_cluster_fit(y_true, y_pred)
    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size

print("""## Visualization

In order to visualize the underlying manifold and the cluster
information we'll rely on an utility function an we'll plot our
results for each run (shallow clusters and clustering of embedded
manifolds)

""")

import seaborn as sns
import pandas as pd

def plot(x, y, plot_id, names=None):
    viz_df = pd.DataFrame(data=x[:5000])
    viz_df['Label'] = y[:5000]
    if names is not None:
        viz_df['Label'] = viz_df['Label'].map(names)

    plt.subplots(figsize=(8, 5))
    plt.title(plot_id)
    sns.scatterplot(x=0, y=1, 
                    hue='Label', legend='full', 
                    hue_order=sorted(viz_df['Label'].unique()),
                    palette=sns.color_palette("hls", n_colors=10),
                    alpha=.5,
                    data=viz_df)
    
    plt.ylabel("")
    plt.xlabel("")
    plt.tight_layout()
    plt.show()
    plt.clf()

print("""## Measures

We'll now proceed to mesure the accuracy and nmi of our model and
compare it againsta a basic clustering algorithm. To do so we will: -
run two basic clusterings (gmm and kmeans) in high dimensions - run
each manifold technique and for every one of them cluster in high
dimensions - visualize the embedded data in high dimension

First let's reshape our test loader to get all the data at once, and
initialize a list to contain our results """)

from sklearn import metrics

# loading all the tests at once
test_loader = torch.utils.data.DataLoader(
    test_data, 
    batch_size=10000, 
    shuffle=False
)

res = []

print("""We can now try simple clustering, and see how it performs""")

if not args.no_shallow:
    with torch.no_grad():
        for x, y in test_loader:
            x = x.view(-1, 784).cpu()
            y = np.asarray(y.numpy())
            
            gmm.fit(x)
            y_pred_prob = gmm.predict_proba(x)
            y_pred = y_pred_prob.argmax(1)

            y_pred = np.asarray(y_pred)
            
            acc = np.round(cluster_acc(y, y_pred), 5)
            nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)
            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)
            
            res += [('GMM', acc, nmi, ari)]
            
            y_pred = np.asarray(km.fit_predict(x))
            
            acc = np.round(cluster_acc(y, y_pred), 5)
            nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)
            ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)
            
            res += [('Km', acc, nmi, ari)]

print("""We'll define an utility function to print a pretty table with our results""")

def print_res(res):
  format = "{:<8} {:<15} {:<10} {:<10}"
  print(format.format("name", "ACC", "NMI", "ARI"))
  for name, acc, nmi, ari in res:
    print(format.format(name, acc, nmi, ari))

print_res(res)

print(""" As we can see the shallow algorithms have a pretty bad result,
they're not really able to cluster the images in a significative way.

## Manifolds

In order to consistently run our mesures we'll first define an helper
function that

- takes the test data: x for the images (viewed as a 784-dimensional
  vector) and y for the label (digit from 0 to 9)

- ecnodes it trough our autoencoder, resulting in a vector of
  dimensionality 2000 (passing trough a bottleneck of dimension 500)

- passes the encoding trough a manifold learner (different each time)

- plots the embedded data, coloring it according to the cluster

- returns the accuracy and nmi mesures along with the name (this is
done because we might want to run the evaluation of the model on
different batch of data, the returned value is a vector of tuples
rapresenting for each batch the accuracy and nmi)

""")

def cluster_embedded(manifold, name):
  res = []
  with torch.no_grad():
    for x, y in test_loader:
        x = x.view(-1, 784).to(device)
        y = np.asarray(y.numpy())
        
        hl = encoder(x)
        
        hle = manifold.fit_transform(hl.cpu())
        gmm.fit(hle)

        y_pred_prob = gmm.predict_proba(hle)
        y_pred = y_pred_prob.argmax(1)
        y_pred = np.asarray(y_pred)

        acc = np.round(cluster_acc(y, y_pred), 5)
        nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)
        ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)

        plot(hle, y, name)
        best_fit, _, _ = best_cluster_fit(y, y_pred)
        plot(hle, best_fit, name)

        res += [(name, acc, nmi, ari)]
  return res

print("""### UMAP manifold

We'll apply `umap` to our encoded space and then cluster it with
`gmm`, mesure its accuracy and nmi and plot the data on a 2d map.

""")

if not args.no_umap:
    res += cluster_embedded(umap_manifold, 'umap')
else:
    print("skipped.")

print("""### t-SNE manifold

We'll apply `t-SNE` to our encoded space and cluster it with `gmm`,
mesure its accuracy and nmi and plot the data on a 2d map.

""")

if not args.no_tsne:
    res += cluster_embedded(tsne_manifold, 't-SNE')
else:
    print("skipped.")

print("""### ISOMAP manifold

We'll apply `isomap` to our encoded space and cluster it with `gmm`,
mesure its accuracy and nmi and plot the data on a 2d map.

""")

if not args.no_isomap:
    res += cluster_embedded(isomap_manifold, 'isomap')
else:
    print("skipped.")

print("""# Results
Finally we can print our total results.

As we can see our experiment confirmed the results of the original
paper. The model outperforms shallow clustering, as `gmm` and `kMeans`
reach a far lower accuracy and normalized mutual information score
than the model, regardless of the manifold embedding we used. Another
observation is that UMAP (focused on local manifold, but with a better
preservation of global manifold) is the best across the bord,
outperforming t-SNE and isomap.

""")

print_res(res)
